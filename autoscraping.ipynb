{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install autoscraper library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autoscraper in c:\\anaconda_program\\lib\\site-packages (1.1.12)\n",
      "Requirement already satisfied: requests in c:\\anaconda_program\\lib\\site-packages (from autoscraper) (2.24.0)\n",
      "Requirement already satisfied: bs4 in c:\\anaconda_program\\lib\\site-packages (from autoscraper) (0.0.1)\n",
      "Requirement already satisfied: lxml in c:\\anaconda_program\\lib\\site-packages (from autoscraper) (4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\anaconda_program\\lib\\site-packages (from requests->autoscraper) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\anaconda_program\\lib\\site-packages (from requests->autoscraper) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda_program\\lib\\site-packages (from requests->autoscraper) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\anaconda_program\\lib\\site-packages (from requests->autoscraper) (2.10)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\anaconda_program\\lib\\site-packages (from bs4->autoscraper) (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\anaconda_program\\lib\\site-packages (from beautifulsoup4->bs4->autoscraper) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install autoscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoscraper import AutoScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://github.com/teja156' #### url of page from which you want to scrap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_list=['stop_phishing','88'] #### the list of things that you want from this particular url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper=AutoScraper()  #### object create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=scraper.build(url,wanted_list) #### build the autoscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['microsoft-teams-class-attender', 'stop_phishing', 'imghide', 'instagram-unfollow-checker', 'thefoodiescript', 'online-classes-prank', '328', '88', '48', '27', '25']\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rule_3o74': ['microsoft-teams-class-attender',\n",
       "  'stop_phishing',\n",
       "  'imghide',\n",
       "  'instagram-unfollow-checker',\n",
       "  'thefoodiescript',\n",
       "  'online-classes-prank'],\n",
       " 'rule_txse': ['328', '88', '48', '27', '25', '25']}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### It basically provide a id to to a particular category.\n",
    "#### And this id is always change when you change something to the model information\n",
    "scraper.get_result_similar(url,grouped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### You provide a allias to each category for better understanding.\n",
    "scraper.set_rule_aliases({'rule_3o74':'Title','rule_txse':'Star'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Youn say to your model to keep these rule for scraping.\n",
    "scraper.keep_rules(['rule_3o74','rule_txse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save your model for future scraping\n",
    "scraper.save('git-info-search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### loading our model\n",
    "scraper.load('git-info-search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Through this model now you can get infromation to different urls belonging to this kind of information. \n",
    "result1=scraper.get_result_similar('https://github.com/Ayush7614',group_by_alias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': ['Daily-Coding-DS-ALGO-Practice', 'Hackerank-Solutions', 'Bundli-Frontend', 'php-college-form-website-project', 'Ayush7614', 'Typescript_Quiz_App'], 'Star': ['11', '4', '4', '2', '2', '2']}\n"
     ]
    }
   ],
   "source": [
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that we can get information of different url but category are same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
